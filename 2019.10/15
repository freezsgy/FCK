今日汇报：
1.准备再补充论文的实验部分，实验部分内容比较少。
2.今天找了一篇论文"Communication-Efficient Learning of Deep Networks from Decentralized Data"。
主要贡献：
这篇论文发现了“识别来自移动设备的分散数据的训练问题”，通过联邦平均算法解决这个问题，然后在一列实验上对算法进行了评估。
结论：
我们的实验表明，联邦学习是可行的，因为FedAvg使用相对较少的通信周期来训练高质量的模型，这在各种模型架构上得到了证明:一个多层感知器、两个不同的卷积NNs、
一个两层字符LSTM和一个大规模的单词级LSTM。提出了和差分隐私和安全多方计算结合可以提供更强的隐私安全保证。（论文细节还没看完）
