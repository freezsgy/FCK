今天看了随机森林。
随机森林是指利用多棵决策树对样本数据进行训练、分类并预测的一种方法，它在对数据进行分类的同时，还可以给出各个变量（基因）的重要性评分，评估各个变量在分类
中所起的作用。随机森林的构建大致如下：首先利用bootstrap方法又放回的从原始训练集中随机抽取n个样本，并构建n个决策树；然后假设在训练样本数据中有m个特征，
那么每次分裂时选择最好的特征进行分裂 每棵树都一直这样分裂下去，直到该节点的所有训练样例都属于同一类；接着让每颗决策树在不做任何修剪的前提下最大限度的生
长；最后将生成的多棵分类树组成随机森林，用随机森林分类器对新的数据进行分类与回归。对于分类问题，按多棵树分类器投票决定最终分类结果；而对于回归问题，则由
多棵树预测值的均值决定最终预测结果。

也了解了深度森林。
 深度森林（gcForest），这是一种决策树集成方法（decision tree ensemble approach），性能较之深度神经网络有很强的竞争力。深度神经网络需要花大力气调参，相比之下
 gcForest 要容易训练得多。实际上，在几乎完全一样的超参数设置下，gcForest 在处理不同领域（domain）的不同数据时，也能达到极佳的性能。gcForest 的训练
 过程效率高且可扩展。在我们的实验中，它在一台 PC 上的训练时间和在 GPU 设施上跑的深度神经网络差不多，有鉴于 gcForest 天然适用于并行的部署，其效率高
 的优势就更为明显。此外，深度神经网络需要大规模的训练数据，而 gcForest 在仅有小规模训练数据的情况下也照常运转。不仅如此，作为一种基于树的方法，
 gcForest 在理论分析方面也应当比深度神经网络更加容易。
