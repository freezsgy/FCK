今日汇报:
今天继续看论文，结合代码了解了这篇论文之所以恢复样本的效果好，
是因为在神经网络中一次只输入一个样本，每次梯度更新只跟这个样本
有关，这个太理想化了。如果batch_size大于1，即批处理样本数大于
1的话效果就不太理想了。一般批处理样本数是多余1的。他这个方法
在前人的论文中出现过。明天看看其中的区别在哪里。
