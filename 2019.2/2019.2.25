恶意网址检测方面主要有3个比较流行的做法：第一个是直接维护一个黑名单，那么下次浏览器在访问某网址的时候，如果该域名已经存在于blacklist中，那么直接阻止访问或弹出警告提醒即可，这种方式最大的一个缺点在于不能及时更新，同时抗干扰能力也比较差，如果人家改了一个域名、或者域名是算法自动生成的，那这种方法就失效了。Heuristic方法是对blacklist的一种扩展，它根据不同的攻击行为设计相应的签名，然后通过扫描网页来检测是否有相应的签名存在，从而判断是否为恶意网址。第二个是用data-driven的方式，即设计良好的特征+机器学习分类模型来实现对恶意网址的自动分类。本文主要介绍基于机器学习的恶意网页检测方法。

要达到比较好的效果，设计良好的特征必不可少。在恶意网页检测方面，特征主要分为两类：静态特征（static）和动态特征（dynamic）。静态特征指的是“在请求URL”的情况下获取特征表示，例如IP地址、域名长度、地理信息、path长度等；动态特征指得是“在执行JS/ActiveX等代码”时系统的行为（记录日志）。静态特征由于不需要预先执行相应的恶意代码，所以相对来讲更安全一些。

目前基于ML的恶意URL检测所用到的特征主要分为一下4类：
1.Blacklist Features：
前面提到过维护一个黑名单数据库来简单粗暴地将URL进行分类，但是这种方案明显不能用于更新迅速的（移动）互联网时代。所以，不直接一锤子买卖判别类型，而将其作为一种特征表示或许是个很不错的方案。有实验表明，将blacklist feature与其他特征的融合，可以取得非常好的效果。目前对黑名单特征有以下几种扩展，来使得该特征更加地robust：
更改顶级域名
根据IP地址
目录的结构相似性
替换查询字符
模糊匹配

2.Lexical Features：
词汇特征，即通过仅仅利用URL链接本身来获取相应的特征表达。例如：URL长度、主机/顶级域名的长度、特定字符的数量、是否包含IP地址、path长度、文件名长度、传参个数等；

3.Host-based Features：
Response Header
IP地址属性
WHOIS信息（域名注册时间、供应商信息等）
地理位置
请求速度
DNS信息

4.Content-based Features：
HTML信息、Javascript信息、Visual信息等

机器学习算法:
1.	批量学习：支持向量机、逻辑回归、 贝叶斯、决策树等

2.	在线学习：积极探索和应用在线学习解决恶意URL检测任务。我们将现有的在线学习算法大致分为两大类:(1)一阶在线算法和(2)二阶在线算法。
1)	一阶在线学习:一阶算法仅利用含有训练数据的一阶信息，通过更新权重向量w进行排序学习。我们简要介绍了一些应用于恶意URL检测的一阶在线算法。
2)	 二阶在线学习:与一阶在线学习不同，二阶在线学习的目的是通过利用二阶信息来提高学习效率，如底层分布的二阶统计量。

3.	表示学习：恶意URL检测有大量和各种各样的特性。特别是，在许多特征类别中使用单词特征包会产生数百万个特征。此外，随着要处理的url数量的增加(在实际环境中是这样的)，特性的数量也在不断增长。使用如此多特性的学习预测模型存在两个主要缺陷: 计算昂贵和噪声模型。
1）	特征选择:特征选择分为两类，根据特征的性能对特征进行评分，然后进行相应的选择。这些是筛选器方法和包装器方法。
2）	稀疏正则化:由于要收集大量的特征，特别是词汇特征，因此需要对数百万个特征进行特征选择。应用筛选器和包装器方法可能不太实际。通过适当修改目标函数可以诱导特征选择，即，(也称为嵌入式方法)。

实际问题和开放问题
高容量、高速度:现实中的URL数据显然是一种高容量、高速度的大数据。2012年8月披露，谷歌搜索引擎在Web上发现了超过30万亿的独立url，每天抓取200亿个站点。

标签获取困难:现有的机器学习恶意URL检测方法大多基于监督学习技术，需要标注好的训练数据，包括良性和恶意的URL数据。

收集特性的困难:如上一节所述，收集表示URL的特性对于应用机器学习技术是至关重要的。

特征表示:除了URL数据的高容量和高速度之外，另一个关键挑战是非常高维的特征(通常以百万甚至十亿的规模)。

概念漂移和新出现的挑战:另一个挑战是概念漂移，由于新威胁和攻击行为的演变，恶意url的分布可能会随着时间的推移而改变。
